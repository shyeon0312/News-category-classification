{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __Prerequisites__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\vaiv\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from eunjeon import Mecab\n",
    "import re\n",
    "\n",
    "nltk.download('punkt')\n",
    "#nltk.download('stopwords')\n",
    "\n",
    "\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "def get_scores(y_test, predicted):\n",
    "    print('-------------------------')\n",
    "    print('Accuracy_score = ', accuracy_score(y_test, predicted))\n",
    "    print('precision_score = ', precision_score(y_test, predicted))\n",
    "    print('recall_score = ', recall_score(y_test, predicted))\n",
    "    print('f1_score = ', f1_score(y_test, predicted))\n",
    "    print('-------------------------\\n')\n",
    "    \n",
    "    confusion_mat = confusion_matrix(y_test, predicted)\n",
    "    print(confusion_mat)\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __Preprocessing__"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 아래에 작성된 data는 뉴스 기사를 크롤링한 데이터입니다.\n",
    "- data의 column은 date, writerName(신문사), title(기사제목), content(기사내용), tag(binary)로 구성되어있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataPreprocessing:\n",
    "    # Get writer_score(ratio of tag_1) : 신문사가 tag==1인 기사를 얼마나 작성하였는지 비율 계산\n",
    "    def get_writer_score(self, data, train=False):\n",
    "        if train == True:\n",
    "            df_writer = data[['writerName', 'tag']].groupby('writerName', as_index=False).sum() # 신문사별 tag==1 개수 추출\n",
    "            df_writer.rename(columns={'tag':'tag_1'}, inplace=True)\n",
    "\n",
    "            total_cnt = data[['writerName', 'tag']].groupby(['writerName'], as_index=False).count()['tag'] # 신문사별 기사 개수 추출\n",
    "            df_writer['total_cnt'] = total_cnt\n",
    "\n",
    "            df_writer['writer_score'] = df_writer['tag_1']/df_writer['total_cnt'] # 신문사별 tag==1인 비율 계산\n",
    "            \n",
    "            df_writer.to_csv('../data/df_writer.csv', index=False)\n",
    "        else:\n",
    "            return\n",
    "\n",
    "    # 기존 DataFrame에 writer_score(신문사별 tag==1인 기사 작성 비율)를 merge\n",
    "    def merge_writer_score(self, data):\n",
    "        df_writer = pd.read_csv('../data/df_writer.csv')\n",
    "        data = pd.merge(data, df_writer[['writerName', 'writer_score']], how='left', on='writerName') # writerName 기준으로 merge\n",
    "        new_data = data[['date', 'writer_score', 'title', 'content', 'tag']]\n",
    "        return new_data\n",
    "    \n",
    "    # 기사 제목을 tf-idf로 벡터화 \n",
    "    def title_tf_idf(self, data, target):\n",
    "        # 1. Mecab 객체 선언\n",
    "        mecab = Mecab()\n",
    "        \n",
    "        # 2. Get nouns from df['title']\n",
    "        x_data = data['title'].apply(lambda x: ' '.join(mecab.nouns(x)))\n",
    "        \n",
    "        # 3-1. Get vector count(By CountVectorizing)\n",
    "        # count_vect = CountVectorizer()\n",
    "        # X_counts = count_vect.fit_transform(x_data)\n",
    "        \n",
    "        # 3-2. Get vector count(By TfidfVectorizing)\n",
    "        tfidf_vect = TfidfVectorizer()\n",
    "        X_counts = tfidf_vect.fit_transform(x_data)\n",
    "        \n",
    "        # 4. Save word vector\n",
    "        #pickle.dump(count_vect.vocabulary_, open(\"count_vector.pkl\",\"wb\"))\n",
    "\n",
    "        # 5. Transform word vector to ti-idf\n",
    "        tfidf_transformer = TfidfTransformer()\n",
    "        X_tfidf = tfidf_transformer.fit_transform(X_counts)\n",
    "        df_tfidf = pd.DataFrame(X_tfidf.toarray())\n",
    "        # df_tfidf['writer_score'] = data['writer_score'] # 추후 분석 시 writer_score를 포함할 경우 주석 제거\n",
    "        df_tfidf.columns = list(map(str, list(df_tfidf.columns)))\n",
    "        # display(df_tfidf)\n",
    "        df_tfidf[target] = data[target]\n",
    "        # df_tfidf['date'] = data['date']\n",
    "\n",
    "        # 6. save tf-idf\n",
    "        # pickle.dump(tfidf_transformer, open(\"tfidf.pkl\",\"wb\"))\n",
    "        return df_tfidf\n",
    "\n",
    "    # Data를 X, y로 나누어 return -> 추후 모델 학습 시 용이한 형태\n",
    "    def data_transformation(self, data, target):\n",
    "        # transform NA to 0\n",
    "        data.fillna(0, inplace=True)\n",
    "        \n",
    "        # make date 0-1\n",
    "        # data['date'] = data['date']/30000000\n",
    "        \n",
    "        # create a feature matrix\n",
    "        X = data.drop(target, axis=1)\n",
    "\n",
    "        # create a target vector\n",
    "        y = data[target]\n",
    "        \n",
    "        # return the feature matrix and target vector\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # write a function to perform data exploration\n",
    "# def perform_data_exploration(file_with_path):\n",
    "    \n",
    "#     # create an object of DataExploration class\n",
    "#     data_exploration = DataExploration()\n",
    "\n",
    "#     # load data HR_comma_sep.csv\n",
    "#     data = data_exploration.load_data(file_with_path)\n",
    "\n",
    "#     # Perform exploration\n",
    "#     data_exploration.data_exploration(data)\n",
    "    \n",
    "#     # explore data\n",
    "#     data_exploration.data_visualization(data)\n",
    "    \n",
    "#     return data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위에서 만든 클래스를 기반으로 데이터를 전처리하는 함수를 구현합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write a function to perform data preprocessing\n",
    "def perform_data_preprocessing(data, target, train=False):\n",
    "    # use DataPreprocessing class to perform data preprocessing\n",
    "    # create an object of DataPreprocessing class\n",
    "    data_preprocessing = DataPreprocessing()\n",
    "\n",
    "    # data_preprocessing.get_writer_score(data, train)\n",
    "    # new_data = data_preprocessing.merge_writer_score(data) # 분석 시 writer_score를 사용하는 경우\n",
    "    new_data = data_preprocessing.title_tf_idf(data, target)\n",
    "\n",
    "    # perform data_transformation\n",
    "    #data_preprocessing.title_transformation(data)\n",
    "    X, y = data_preprocessing.data_transformation(new_data, target)\n",
    "\n",
    "    return  X, y\n",
    "\n",
    "def data_splitting(X, y):\n",
    "    # split the data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                        y,\n",
    "                                                        test_size=0.2,\n",
    "                                                        random_state=1004)\n",
    "\n",
    "    # return the training and testing sets\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __사용 예시__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/train_data.xlsx'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_1200\\61275471.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'../data/train_data.xlsx'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdf_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'../data/news_20230308.xlsx'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mdf_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'tag'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\vaiv\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                 )\n\u001b[1;32m--> 311\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\vaiv\\anaconda3\\lib\\site-packages\\pandas\\io\\excel\\_base.py\u001b[0m in \u001b[0;36mread_excel\u001b[1;34m(io, sheet_name, header, names, index_col, usecols, squeeze, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, thousands, decimal, comment, skipfooter, convert_float, mangle_dupe_cols, storage_options)\u001b[0m\n\u001b[0;32m    455\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m         \u001b[0mshould_close\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 457\u001b[1;33m         \u001b[0mio\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    458\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m         raise ValueError(\n",
      "\u001b[1;32mc:\\Users\\vaiv\\anaconda3\\lib\\site-packages\\pandas\\io\\excel\\_base.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, path_or_buffer, engine, storage_options)\u001b[0m\n\u001b[0;32m   1374\u001b[0m                 \u001b[0mext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"xls\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1375\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1376\u001b[1;33m                 ext = inspect_excel_format(\n\u001b[0m\u001b[0;32m   1377\u001b[0m                     \u001b[0mcontent_or_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1378\u001b[0m                 )\n",
      "\u001b[1;32mc:\\Users\\vaiv\\anaconda3\\lib\\site-packages\\pandas\\io\\excel\\_base.py\u001b[0m in \u001b[0;36minspect_excel_format\u001b[1;34m(content_or_path, storage_options)\u001b[0m\n\u001b[0;32m   1248\u001b[0m         \u001b[0mcontent_or_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcontent_or_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1249\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1250\u001b[1;33m     with get_handle(\n\u001b[0m\u001b[0;32m   1251\u001b[0m         \u001b[0mcontent_or_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_text\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1252\u001b[0m     ) as handle:\n",
      "\u001b[1;32mc:\\Users\\vaiv\\anaconda3\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    793\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    794\u001b[0m             \u001b[1;31m# Binary mode\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 795\u001b[1;33m             \u001b[0mhandle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    796\u001b[0m         \u001b[0mhandles\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    797\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/train_data.xlsx'"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_excel('../data/train_data.xlsx')\n",
    "df_test = pd.read_excel('../data/news_20230308.xlsx')\n",
    "df_test['tag'] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>docID</th>\n",
       "      <th>date</th>\n",
       "      <th>writerName</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>section</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>20230214</td>\n",
       "      <td>머니S</td>\n",
       "      <td>정부, AI반도체 석·박사 집중 육성… 대학당 '6년간 164억원' 지원</td>\n",
       "      <td>정부가 미국 AI 개발업체인 '오픈AI'(OpenAI)의 '챗GPT'(ChatGPT...</td>\n",
       "      <td>IT/과학</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20230215</td>\n",
       "      <td>뉴시스</td>\n",
       "      <td>인사 청탁 대가 금품수수 의혹 전 소방청장 영장 기각</td>\n",
       "      <td>기사내용 요약 법원 \"피의 사실 일부 다툼 여지, 불구속 상태 방어권 보장 필요\" ...</td>\n",
       "      <td>사회</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>20230214</td>\n",
       "      <td>아이뉴스24</td>\n",
       "      <td>튀르키예 강진에 우리나라 지하수가 출렁였다</td>\n",
       "      <td>튀르키예에서 발생한 강진에 우리나라의 지하수가 출렁였다는 관측 보고가 나왔다. 한국...</td>\n",
       "      <td>IT/과학</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>20230215</td>\n",
       "      <td>데일리안</td>\n",
       "      <td>멸치쇼핑, 2023년 신입 및 경력 사원 대규모 공채 진행</td>\n",
       "      <td>[데일리안 = 박영민 기자] 오픈마켓 멸치쇼핑이 2023년 신입 및 경력 사원을 대...</td>\n",
       "      <td>생활/문화</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>20230111</td>\n",
       "      <td>뉴스1</td>\n",
       "      <td>美국방부, 추모의 벽 전사자 명단 오류에 \"유감스러운 실수\"</td>\n",
       "      <td>국방부 대변인 \"실수 바로잡기 위해 내무부와 협력\"…'오류 발견' 가족 등에 연락 ...</td>\n",
       "      <td>정치외교</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   docID      date writerName                                     title  \\\n",
       "0      1  20230214        머니S  정부, AI반도체 석·박사 집중 육성… 대학당 '6년간 164억원' 지원   \n",
       "1      2  20230215        뉴시스             인사 청탁 대가 금품수수 의혹 전 소방청장 영장 기각   \n",
       "2      3  20230214     아이뉴스24                   튀르키예 강진에 우리나라 지하수가 출렁였다   \n",
       "3      4  20230215       데일리안          멸치쇼핑, 2023년 신입 및 경력 사원 대규모 공채 진행   \n",
       "4      5  20230111        뉴스1         美국방부, 추모의 벽 전사자 명단 오류에 \"유감스러운 실수\"   \n",
       "\n",
       "                                             content section  tag  \n",
       "0  정부가 미국 AI 개발업체인 '오픈AI'(OpenAI)의 '챗GPT'(ChatGPT...   IT/과학    0  \n",
       "1  기사내용 요약 법원 \"피의 사실 일부 다툼 여지, 불구속 상태 방어권 보장 필요\" ...      사회    0  \n",
       "2  튀르키예에서 발생한 강진에 우리나라의 지하수가 출렁였다는 관측 보고가 나왔다. 한국...   IT/과학    0  \n",
       "3  [데일리안 = 박영민 기자] 오픈마켓 멸치쇼핑이 2023년 신입 및 경력 사원을 대...   생활/문화    0  \n",
       "4  국방부 대변인 \"실수 바로잡기 위해 내무부와 협력\"…'오류 발견' 가족 등에 연락 ...    정치외교    1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 학습할 데이터와 테스트할 데이터가 한 파일 내에 있다면 train=True로 진행하면 됩니다.\n",
    "- 학습 데이터와 테스트 데이터가 분리된 파일로 존재한다면 train=False로 진행하면 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TRAIN & TEST SET\n",
    "\n",
    "train = True  # train set으로만 결과 확인 시 True\n",
    "\n",
    "df = pd.concat([df_train, df_test], ignore_index=True)\n",
    "X, y = perform_data_preprocessing(data=df, target='tag', train=train)\n",
    "\n",
    "if train:\n",
    "    X, y = perform_data_preprocessing(data=df_train, target='tag', train=train)\n",
    "    X_train, X_test, y_train, y_test = data_splitting(X, y)\n",
    "else:\n",
    "    df = pd.concat([df_train, df_test], ignore_index=True)\n",
    "    X, y = perform_data_preprocessing(data=df, target='tag', train=train)   \n",
    "    X_train = X[:len(df_train)]; X_test = X[len(df_train):]\n",
    "    y_train = y[:len(df_train)]; y_test = y[len(df_train):]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __Modeling__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Train logistic regression model\n",
    "classifier = LogisticRegression(random_state=42)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "predicted = classifier.predict(X_test)\n",
    "predicted_prob = classifier.predict_proba(X_test)\n",
    "\n",
    "if train :\n",
    "    result_nb = pd.DataFrame({'true_labels':y_test, 'predicted_labels':predicted})\n",
    "    print('Logistic Regression')\n",
    "    get_scores(y_test, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multinomial Naive Bayes\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "clf = MultinomialNB().fit(X_train, y_train)\n",
    "#pickle.dump(clf, open(\"svm.pkl\", \"wb\"))\n",
    "\n",
    "#SAVE MODEL\n",
    "#pickle.dump(clf, open(\"nb_model.pkl\", \"wb\"))\n",
    "\n",
    "predicted = clf.predict(X_test)\n",
    "predicted_prob = clf.predict_proba(X_test)\n",
    "\n",
    "if train:\n",
    "    result_nb = pd.DataFrame({'true_labels':y_test, 'predicted_labels':predicted})\n",
    "\n",
    "    print('Naive_Bayes')\n",
    "    get_scores(y_test, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "clf_neural = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(128,), max_iter=10000, random_state=1)\n",
    "clf_neural.fit(X_train, y_train)\n",
    "pickle.dump(clf_neural, open(\"softmax.pkl\", \"wb\"))\n",
    "\n",
    "predicted = clf_neural.predict(X_test)\n",
    "predicted_prob = clf_neural.predict_proba(X_test)\n",
    "\n",
    "\n",
    "\n",
    "if train:\n",
    "    result_svm = pd.DataFrame({'true_labels':y_test, 'predicted_labels':predicted})\n",
    "\n",
    "    print('Softmax')\n",
    "    get_scores(y_test, predicted)\n",
    "else:\n",
    "    df_proba = pd.DataFrame(predicted_prob).rename(columns={0:'prob_0', 1:'prob_1'})\n",
    "    df_test['tag'] = predicted\n",
    "    df_test['prob_0'] = df_proba['prob_0']\n",
    "    df_test['prob_1'] = df_proba['prob_1']\n",
    "    \n",
    "    # df_test.to_csv('../data/result_ksh_2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "clf_svm = svm.LinearSVC()\n",
    "clf_svm.fit(X_train, y_train)\n",
    "\n",
    "#pickle.dump(clf_svm, open(\"svm.pkl\", \"wb\"))\n",
    "\n",
    "predicted = clf_svm.predict(X_test)\n",
    "\n",
    "if train:\n",
    "    result_svm = pd.DataFrame({'true_labels':y_test, 'predicted_labels':predicted})\n",
    "\n",
    "    print('SVM')\n",
    "    get_scores(y_test, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn import svm\n",
    "\n",
    "clf_svm = svm.LinearSVC()\n",
    "clf = CalibratedClassifierCV(clf_svm, method='sigmoid') \n",
    "clf.fit(X_train, y_train)\n",
    "y_proba = clf.predict_proba(X_test)\n",
    "\n",
    "#pickle.dump(clf_svm, open(\"svm.pkl\", \"wb\"))\n",
    "\n",
    "predicted = clf.predict(X_test)\n",
    "\n",
    "if train:\n",
    "    result_svm = pd.DataFrame({'true_labels':y_test, 'predicted_labels':predicted})\n",
    "\n",
    "    print('SVM')\n",
    "    get_scores(y_test, predicted)\n",
    "else:\n",
    "    df_proba = pd.DataFrame(y_proba).rename(columns={0:'prob_0', 1:'prob_1'})\n",
    "    df_test['tag'] = predicted\n",
    "    df_test['prob_0'] = df_proba['prob_0']\n",
    "    df_test['prob_1'] = df_proba['prob_1']\n",
    "    \n",
    "    df_test.to_csv('../data/result_tag.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    5945\n",
       "1    1426\n",
       "Name: tag, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test['tag'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "사회       3509\n",
       "경제       1774\n",
       "정치       1129\n",
       "세계        357\n",
       "생활/문화     328\n",
       "IT/과학     274\n",
       "Name: section, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test['section'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    579\n",
       "1    550\n",
       "Name: tag, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test[df_test['section']=='정치']['tag'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "정치       550\n",
       "사회       486\n",
       "경제       195\n",
       "세계       157\n",
       "IT/과학     20\n",
       "생활/문화     18\n",
       "Name: section, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test[df_test['tag']==1]['section'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>docID</th>\n",
       "      <th>date</th>\n",
       "      <th>writerName</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>section</th>\n",
       "      <th>tag</th>\n",
       "      <th>prob_0</th>\n",
       "      <th>prob_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>202303080030011730048</td>\n",
       "      <td>20230308</td>\n",
       "      <td>뉴시스</td>\n",
       "      <td>WBC 대한민국 vs 호주, 기자회견하는 양팀 감독들</td>\n",
       "      <td>[도쿄=뉴시스] 김선웅 기자 = WBC 대한민국 야구대표팀 이강철 감독과 호주대표팀...</td>\n",
       "      <td>세계</td>\n",
       "      <td>0</td>\n",
       "      <td>0.577398</td>\n",
       "      <td>0.422602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>202303080030011729801</td>\n",
       "      <td>20230308</td>\n",
       "      <td>뉴시스</td>\n",
       "      <td>이강철 야구대표팀 감독, 기자회견</td>\n",
       "      <td>[도쿄=뉴시스] 김선웅 기자 = WBC 대한민국 야구대표팀 이강철 감독이 8일 일본...</td>\n",
       "      <td>세계</td>\n",
       "      <td>0</td>\n",
       "      <td>0.936086</td>\n",
       "      <td>0.063914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>202303080030011729793</td>\n",
       "      <td>20230308</td>\n",
       "      <td>뉴시스</td>\n",
       "      <td>밝은 표정으로 기자회견하는 이강철 감독</td>\n",
       "      <td>[도쿄=뉴시스] 김선웅 기자 = WBC 대한민국 야구대표팀 이강철 감독이 8일 일본...</td>\n",
       "      <td>세계</td>\n",
       "      <td>0</td>\n",
       "      <td>0.864316</td>\n",
       "      <td>0.135684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>202303080030011729791</td>\n",
       "      <td>20230308</td>\n",
       "      <td>뉴시스</td>\n",
       "      <td>기자회견하는 김현수</td>\n",
       "      <td>[도쿄=뉴시스] 김선웅 기자 = WBC 대한민국 야구대표팀 주장 김현수가 8일 일본...</td>\n",
       "      <td>세계</td>\n",
       "      <td>0</td>\n",
       "      <td>0.720959</td>\n",
       "      <td>0.279041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>202303084210006671416</td>\n",
       "      <td>20230308</td>\n",
       "      <td>뉴스1</td>\n",
       "      <td>기자회견 참석한 中 외교부장</td>\n",
       "      <td>(베이징 AFP=뉴스1) 김성식 기자 = 친강 중국 외교부장이 7일 중국 베이징 전...</td>\n",
       "      <td>세계</td>\n",
       "      <td>1</td>\n",
       "      <td>0.024120</td>\n",
       "      <td>0.975880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7347</th>\n",
       "      <td>202303084210006670227</td>\n",
       "      <td>20230308</td>\n",
       "      <td>뉴스1</td>\n",
       "      <td>파월 \"최종 금리 수준, 이전 예상보다 더 높을 가능성 커\"(1보)</td>\n",
       "      <td>(서울=뉴스1) 김민수 기자 = 제롬 파월 연방준비제도(연준) 의장은 7일(현지시간...</td>\n",
       "      <td>세계</td>\n",
       "      <td>1</td>\n",
       "      <td>0.270165</td>\n",
       "      <td>0.729835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7357</th>\n",
       "      <td>202303080250003264218</td>\n",
       "      <td>20230308</td>\n",
       "      <td>중앙일보</td>\n",
       "      <td>[사진] “대만은 중국 영토” 헌법 읽는 친강 외교부장</td>\n",
       "      <td>친강 중국 외교부장이 7일 취임 후 첫 기자회견에서 대만 관련 질문이 나오자 붉은 ...</td>\n",
       "      <td>세계</td>\n",
       "      <td>1</td>\n",
       "      <td>0.009092</td>\n",
       "      <td>0.990908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7363</th>\n",
       "      <td>202303080150004818282</td>\n",
       "      <td>20230308</td>\n",
       "      <td>한국경제</td>\n",
       "      <td>백악관 \"윤 대통령, 4월26일 국빈 방문…동맹 70년 기념\" [종합]</td>\n",
       "      <td>7일(현지시간) 미국 백악관은 윤석열 대통령이 다음 달 26일 미국을 국빈 방문한다...</td>\n",
       "      <td>세계</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000988</td>\n",
       "      <td>0.999012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7366</th>\n",
       "      <td>202303080030011728700</td>\n",
       "      <td>20230308</td>\n",
       "      <td>뉴시스</td>\n",
       "      <td>방글라데시 다카서 상가 건물 폭발…최소 14명 사망</td>\n",
       "      <td>기사내용 요약 50명 이상 부상…폭발 충격에 건물 1~2층 크게 파손 [다카(방글라...</td>\n",
       "      <td>세계</td>\n",
       "      <td>0</td>\n",
       "      <td>0.892633</td>\n",
       "      <td>0.107367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7368</th>\n",
       "      <td>202303084210006670233</td>\n",
       "      <td>20230308</td>\n",
       "      <td>뉴스1</td>\n",
       "      <td>美파월, 최종금리 상향 언급…\"금리 인상 폭 높일 준비 돼 있다\"(종합)</td>\n",
       "      <td>\"인플레이션 2%까지 낮추는 과정은 멀고도 험난한 길이 될 것\" 최대 고용 및 물가...</td>\n",
       "      <td>세계</td>\n",
       "      <td>1</td>\n",
       "      <td>0.116263</td>\n",
       "      <td>0.883737</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>357 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      docID      date writerName  \\\n",
       "10    202303080030011730048  20230308        뉴시스   \n",
       "12    202303080030011729801  20230308        뉴시스   \n",
       "13    202303080030011729793  20230308        뉴시스   \n",
       "14    202303080030011729791  20230308        뉴시스   \n",
       "22    202303084210006671416  20230308        뉴스1   \n",
       "...                     ...       ...        ...   \n",
       "7347  202303084210006670227  20230308        뉴스1   \n",
       "7357  202303080250003264218  20230308       중앙일보   \n",
       "7363  202303080150004818282  20230308       한국경제   \n",
       "7366  202303080030011728700  20230308        뉴시스   \n",
       "7368  202303084210006670233  20230308        뉴스1   \n",
       "\n",
       "                                         title  \\\n",
       "10               WBC 대한민국 vs 호주, 기자회견하는 양팀 감독들   \n",
       "12                          이강철 야구대표팀 감독, 기자회견   \n",
       "13                       밝은 표정으로 기자회견하는 이강철 감독   \n",
       "14                                  기자회견하는 김현수   \n",
       "22                             기자회견 참석한 中 외교부장   \n",
       "...                                        ...   \n",
       "7347     파월 \"최종 금리 수준, 이전 예상보다 더 높을 가능성 커\"(1보)   \n",
       "7357            [사진] “대만은 중국 영토” 헌법 읽는 친강 외교부장   \n",
       "7363   백악관 \"윤 대통령, 4월26일 국빈 방문…동맹 70년 기념\" [종합]   \n",
       "7366              방글라데시 다카서 상가 건물 폭발…최소 14명 사망   \n",
       "7368  美파월, 최종금리 상향 언급…\"금리 인상 폭 높일 준비 돼 있다\"(종합)   \n",
       "\n",
       "                                                content section  tag  \\\n",
       "10    [도쿄=뉴시스] 김선웅 기자 = WBC 대한민국 야구대표팀 이강철 감독과 호주대표팀...      세계    0   \n",
       "12    [도쿄=뉴시스] 김선웅 기자 = WBC 대한민국 야구대표팀 이강철 감독이 8일 일본...      세계    0   \n",
       "13    [도쿄=뉴시스] 김선웅 기자 = WBC 대한민국 야구대표팀 이강철 감독이 8일 일본...      세계    0   \n",
       "14    [도쿄=뉴시스] 김선웅 기자 = WBC 대한민국 야구대표팀 주장 김현수가 8일 일본...      세계    0   \n",
       "22    (베이징 AFP=뉴스1) 김성식 기자 = 친강 중국 외교부장이 7일 중국 베이징 전...      세계    1   \n",
       "...                                                 ...     ...  ...   \n",
       "7347  (서울=뉴스1) 김민수 기자 = 제롬 파월 연방준비제도(연준) 의장은 7일(현지시간...      세계    1   \n",
       "7357  친강 중국 외교부장이 7일 취임 후 첫 기자회견에서 대만 관련 질문이 나오자 붉은 ...      세계    1   \n",
       "7363  7일(현지시간) 미국 백악관은 윤석열 대통령이 다음 달 26일 미국을 국빈 방문한다...      세계    1   \n",
       "7366  기사내용 요약 50명 이상 부상…폭발 충격에 건물 1~2층 크게 파손 [다카(방글라...      세계    0   \n",
       "7368  \"인플레이션 2%까지 낮추는 과정은 멀고도 험난한 길이 될 것\" 최대 고용 및 물가...      세계    1   \n",
       "\n",
       "        prob_0    prob_1  \n",
       "10    0.577398  0.422602  \n",
       "12    0.936086  0.063914  \n",
       "13    0.864316  0.135684  \n",
       "14    0.720959  0.279041  \n",
       "22    0.024120  0.975880  \n",
       "...        ...       ...  \n",
       "7347  0.270165  0.729835  \n",
       "7357  0.009092  0.990908  \n",
       "7363  0.000988  0.999012  \n",
       "7366  0.892633  0.107367  \n",
       "7368  0.116263  0.883737  \n",
       "\n",
       "[357 rows x 9 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test[df_test['section']=='세계']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tag_1 = df_test[df_test['tag']==1]\n",
    "df_tag_1.to_csv('../data/result_tag1.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e650a76af8b61bac68830ccd08220010f4794930f80523975eef46125932fe32"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
